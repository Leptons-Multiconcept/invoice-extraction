{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM6S8sQ4ZG/TxhBoIqLcSD0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Leptons-Multiconcept/invoice-extraction/blob/main/InvoiceExtraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qNLhakmjUkuk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76b7de3c-a2c4-4ef3-e524-dd3ca50d8406"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/160.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m122.9/160.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.8/160.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/760.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m757.8/760.0 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m760.0/760.0 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U google-generativeai\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai"
      ],
      "metadata": {
        "id": "icKOgRrPVRyu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "IhnZ5-khVb2_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "id": "iETYCtRUWD12",
        "outputId": "e711cea6-8672-4dc1-a84e-45b8f8c44456"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro\n",
            "models/gemini-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-pro-vision\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-1.5-pro-001\n",
            "models/gemini-1.5-pro-002\n",
            "models/gemini-1.5-pro\n",
            "models/gemini-1.5-pro-exp-0801\n",
            "models/gemini-1.5-pro-exp-0827\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-flash-001\n",
            "models/gemini-1.5-flash-001-tuning\n",
            "models/gemini-1.5-flash\n",
            "models/gemini-1.5-flash-exp-0827\n",
            "models/gemini-1.5-flash-002\n",
            "models/gemini-1.5-flash-8b\n",
            "models/gemini-1.5-flash-8b-001\n",
            "models/gemini-1.5-flash-8b-latest\n",
            "models/gemini-1.5-flash-8b-exp-0827\n",
            "models/gemini-1.5-flash-8b-exp-0924\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Configuration\n",
        "\n",
        "MODEL_CONVIG ={\n",
        "    'temperature': 0.2,\n",
        "    'top_k': 32,\n",
        "    'top_p': 1,\n",
        "    'max_output_tokens': 4096,\n",
        "}\n",
        "\n",
        "## Safety Settings of Model\n",
        "safety_settings = [\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\",\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\",\n",
        "\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\",\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\",\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "nOJp0hSzYdc1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load GEMINI Model with Model Configuration"
      ],
      "metadata": {
        "id": "tBnJOaN3aBO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(\n",
        "    model_name='gemini-1.5-flash',\n",
        "    generation_config=MODEL_CONVIG,\n",
        "    safety_settings=safety_settings\n",
        ")"
      ],
      "metadata": {
        "id": "9tbHTILnZ28V"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Image Format to Input in Gemini"
      ],
      "metadata": {
        "id": "xk4Hx3lwbHQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "def image_format(image_path):\n",
        "  img = Path(image_path)\n",
        "\n",
        "  if not img.exists():\n",
        "    raise FileNotFoundError(f\"Could not find image: {img}\")\n",
        "\n",
        "\n",
        "  image_paths = [\n",
        "      {\n",
        "          'mime_type': 'image/jpeg',\n",
        "          'data': img.read_bytes()\n",
        "      }\n",
        "  ]\n",
        "  return image_paths"
      ],
      "metadata": {
        "id": "9GaolddSamwH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gemini Model Output"
      ],
      "metadata": {
        "id": "gthQPyp8cMeR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gemini_output(image_path, system_prompt, user_prompt):\n",
        "  image_info = image_format(image_path)\n",
        "  input_prompt = [system_prompt, image_info[0], user_prompt]\n",
        "  response = model.generate_content(input_prompt)\n",
        "  return response.text"
      ],
      "metadata": {
        "id": "Io-nTBcEcJ60"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extracting Part of the Information From Invoice"
      ],
      "metadata": {
        "id": "8bCilmDLdDmy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"\"\"\n",
        "                You are a specialist in comprehending reciepts.\n",
        "                Input images in the form of reciepts will be provided to you,\n",
        "                and your task is to respond to questions based on the content of the input image.\n",
        "                \"\"\"\n",
        "image_path = '/content/invoice.png'\n",
        "\n",
        "user_prompt = 'What is the invoice number?'\n",
        "\n",
        "gemini_output(image_path, system_prompt, user_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ho6GBnNdc9_v",
        "outputId": "b91778c0-655d-4676-feb6-f9145c817557"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The invoice number is 12345.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extracting Whole Data in JSON from Invoice"
      ],
      "metadata": {
        "id": "cPkd8gEQkIkg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"\"\"\n",
        "                You are a specialist in comprehending reciepts.\n",
        "                Input images in the form of reciepts will be provided to you,\n",
        "                and your task is to respond to questions based on the content of the input image.\n",
        "                Convert invoice data into JSON format with approprait JSON tags as required for the data in image.\n",
        "                \"\"\"\n",
        "image_path = '/content/invoice.png'\n",
        "\n",
        "user_prompt = 'Convert invoice data into JSON format with appropraite JSON tags as required.'\n"
      ],
      "metadata": {
        "id": "hE3KKnTmhQTd"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = gemini_output(image_path, system_prompt, user_prompt)"
      ],
      "metadata": {
        "id": "kOY4SBcQk17e"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown\n",
        "Markdown(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        },
        "id": "ClsLdNj8lHfd",
        "outputId": "26cdc821-0c98-4564-e6cf-7c743eaeedbd"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```json\n{\n  \"invoice_number\": \"12345\",\n  \"invoice_date\": \"16 June 2025\",\n  \"bill_to\": {\n    \"name\": \"Imani Olowe\",\n    \"phone\": \"+123-456-7890\",\n    \"address\": \"63 Ivy Road, Hawkville, GA, USA 31036\"\n  },\n  \"items\": [\n    {\n      \"item\": \"Eggshell Camisole Top\",\n      \"quantity\": 1,\n      \"unit_price\": 123,\n      \"total\": 123\n    },\n    {\n      \"item\": \"Cuban Collar Shirt\",\n      \"quantity\": 2,\n      \"unit_price\": 127,\n      \"total\": 254\n    },\n    {\n      \"item\": \"Floral Cotton Dress\",\n      \"quantity\": 1,\n      \"unit_price\": 123,\n      \"total\": 123\n    }\n  ],\n  \"subtotal\": 500,\n  \"tax\": 0,\n  \"total\": 500,\n  \"payment_information\": {\n    \"bank\": \"Briard Bank\",\n    \"account_name\": \"Samira Hadid\",\n    \"account_number\": \"123-456-7890\",\n    \"due_date\": \"5 July 2025\"\n  },\n  \"seller\": {\n    \"name\": \"Samira Hadid\",\n    \"address\": \"123 Anywhere St., Any City, ST 12345\"\n  }\n}\n```"
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R2m54zMplT2J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}